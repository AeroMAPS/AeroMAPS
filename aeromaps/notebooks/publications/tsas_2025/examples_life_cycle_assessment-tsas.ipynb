{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Life Cycle Assessment - TSAS scenarios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load modules\n",
    "\n",
    "First, the user has to load the framework and generate a process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "from aeromaps import create_process\n",
    "from aeromaps.core.models import (\n",
    "    models_traffic,\n",
    "    models_efficiency_top_down_interp,\n",
    "    models_energy_with_fuel_effect,\n",
    "    models_offset,\n",
    "    models_climate_fair,\n",
    "    models_energy_cost_complex,\n",
    "    models_operation_cost_top_down,\n",
    "    models_abatements_cost_simplified,\n",
    ")\n",
    "from aeromaps.models.impacts.life_cycle_assessment.life_cycle_assessment import LifeCycleAssessment\n",
    "import brightway2 as bw\n",
    "import lca_algebraic as agb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import math\n",
    "import collections\n",
    "import time\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"models_traffic\": models_traffic,\n",
    "    \"models_efficiency_top_down_interp\": models_efficiency_top_down_interp,\n",
    "    \"models_energy_with_fuel_effect\": models_energy_with_fuel_effect,\n",
    "    \"models_offset\": models_offset,\n",
    "    \"models_climate_fair\": models_climate_fair,\n",
    "    \"models_energy_cost_complex\": models_energy_cost_complex,\n",
    "    \"models_operation_cost_top_down\": models_operation_cost_top_down,\n",
    "    \"models_abatements_cost_simplified\": models_abatements_cost_simplified,\n",
    "    \"life_cycle_assessment\": LifeCycleAssessment(\n",
    "        name=\"life_cycle_assessment\",\n",
    "        configuration_file=\"./data/lca_data/configuration_file_lca_tsas.yaml\",\n",
    "        split_by=\"phase\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bw.databases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create process from scenario (previously calculated)\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is0medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### b) Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "process.compute()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Results and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_data_vector_outputs_scenario_1 = process.data['vector_outputs']\n",
    "process_data_float_inputs_scenario_1 = process.data['float_inputs']\n",
    "process_data_climate_scenario_1 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_1 = process.data['lca_outputs']\n",
    "lca_outputs_scenario_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_stacked_evolution_subplots(xarray_data):\n",
    "    \n",
    "    df = xarray_data.to_dataframe().reset_index()\n",
    "    \n",
    "    # Set the desired columns as a MultiIndex\n",
    "    df = df.set_index(['impacts', 'axis', 'year'])\n",
    "    \n",
    "    # Pivot the DataFrame to have years as columns\n",
    "    df = df.pivot_table(values='lca', index=['impacts', 'axis'], columns='year')\n",
    "    \n",
    "    # Remove phases containing 'sum'\n",
    "    df_filtered = df[~df.index.get_level_values('axis').str.contains('sum')]\n",
    "    df_filtered = df_filtered[~df_filtered.index.get_level_values('axis').str.contains('_other_')]  # make sure it is equal to zero before deleting\n",
    "    \n",
    "    methods = df_filtered.index.get_level_values('impacts').unique()#[:9]\n",
    "    years = df_filtered.columns\n",
    "    \n",
    "    # Determine the number of rows and columns for the subplots\n",
    "    n_methods = len(methods)\n",
    "    n_cols = 3 #2 if n_methods % 2 == 0 else 3\n",
    "    n_rows = math.ceil(n_methods / n_cols)\n",
    "    \n",
    "    # Use seaborn color palette for better aesthetics\n",
    "    palette = sns.color_palette(\"Set2\", len(df_filtered.index.levels[1]))\n",
    "    #palette = sns.color_palette(\"Paired\", len(df_filtered.index.levels[1]))\n",
    "    palette_dict = {\n",
    "        'aircraft_production': (palette[3], ''),\n",
    "        'airport': (palette[1], ''),\n",
    "        'kerosene_production': (palette[2], ''),\n",
    "        'biofuel_production': (palette[5], ''),\n",
    "        'e_fuel_production': (palette[8], ''),\n",
    "        'hydrogen_production': (palette[6], ''),\n",
    "        'CO2 from combustion': (palette[7], ''),\n",
    "        \"Non-CO2 from combustion\": ('0.8', '//'),\n",
    "        #'Production Electrofuel\\n(Electrolysis)': ('0.8', '\\\\'),\n",
    "        #'production_kerosene': (palette[8], ''),\n",
    "    }\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 4), constrained_layout=False)\n",
    "    axes = axes.flatten()  # Flatten the array of axes for easy iteration\n",
    "\n",
    "    for i, method in enumerate(methods):\n",
    "        df_method = df_filtered.xs(method, level='impacts')\n",
    "        df_method.index = df_method.index.str.replace('_other_', 'Others')\n",
    "\n",
    "        # Group CO2 emissions together\n",
    "        co2_rows = df_method.index.str.startswith('CO2')\n",
    "        co2_aggregated = df_method[co2_rows].sum()\n",
    "        co2_aggregated.name = \"CO2 from combustion\"\n",
    "        df_method = pd.concat([df_method[~co2_rows], co2_aggregated.to_frame().T], ignore_index=False) \n",
    "\n",
    "        # Group non-CO2 emissions together\n",
    "        nonco2_rows = df_method.index.str.startswith('non_CO2')\n",
    "        nonco2_aggregated = df_method[nonco2_rows].sum()\n",
    "        nonco2_aggregated.name = \"Non-CO2 from combustion\"\n",
    "        df_method = pd.concat([df_method[~nonco2_rows], nonco2_aggregated.to_frame().T], ignore_index=False) \n",
    "        \n",
    "        # Remove elements with no contribution to score\n",
    "        df_method = df_method.loc[~(df_method.eq(0).all(axis=1))]\n",
    "        \n",
    "        # Plot stacked area chart with custom colors\n",
    "        #stacks = axes[i].stackplot(years, df_method, labels=df_method.index, alpha=0.8, colors=palette)\n",
    "        colors = [palette_dict[key][0] for key in df_method.index]\n",
    "        stacks = axes[i].stackplot(years, df_method, labels=df_method.index, alpha=0.8, colors=colors, linewidth=0.2)\n",
    "        \n",
    "        # Customize the subplot\n",
    "        name = method[2]\n",
    "        #name = name.replace('- ', '\\n').replace('(', '\\n(')\n",
    "        name = name.replace('(with non-CO2)', '')\n",
    "        name = name.replace('total', '')\n",
    "        name = name.split('- ')[0]\n",
    "        name = name.replace(':', '\\n')\n",
    "        name = \"\".join([a if a.isupper() else b for a,b in zip(name,name.title())])\n",
    "        \n",
    "        unit = bw.Method(method).metadata.get('unit')\n",
    "        unit = unit.replace(']', '')\n",
    "        unit = unit.replace('m2*a crop-Eq', r'm$^2\\times$yr annual crop land')\n",
    "        unit = unit.replace('-Eq', '-eq')\n",
    "        unit = unit.replace('CO2', r'CO$_2$')\n",
    "        \n",
    "        axes[i].set_title(name, fontsize=12)\n",
    "        axes[i].set_xlabel('Year')\n",
    "        axes[i].set_ylabel(unit)\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_axisbelow(True)\n",
    "        axes[i].ticklabel_format(axis='y', scilimits=(0,4))\n",
    "        axes[i].set_facecolor('white')\n",
    "\n",
    "        # Set hatches pattern\n",
    "        hatches = [palette_dict[key][1] for key in df_method.index]\n",
    "        for stack, hatch, values in zip(stacks, hatches, df_method.values):\n",
    "            if np.any(values != 0):  # Check if the layer has non-zero values\n",
    "                stack.set_edgecolor('0.1')\n",
    "            #stack.set_edgecolor(color)\n",
    "            if hatch:\n",
    "                stack.set_hatch(hatch)\n",
    "    \n",
    "    # Collect legend labels from all plots.\n",
    "    all_handles = []\n",
    "    all_labels = []\n",
    "    for ax in axes: \n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        all_handles.extend(handles)\n",
    "        all_labels.extend(labels)\n",
    "    \n",
    "    entries = collections.OrderedDict()\n",
    "    for ax in axes.flatten():\n",
    "        for handle, label in zip(all_handles, all_labels):\n",
    "            #if 'biofuel' in label or 'electrofuel' in label:\n",
    "            #    continue\n",
    "            if label == 'Others':\n",
    "                continue\n",
    "            if \"CO2\" in label:\n",
    "                label_name = label.replace('CO2', r'CO$_2$')\n",
    "            elif \"e_fuel\" in label:\n",
    "                label_name = label.replace('e_fuel', 'E-Fuel').replace('_', ' ').title()\n",
    "            else:\n",
    "                label_name = label.replace('_', ' ').title()\n",
    "            entries[label_name] = handle\n",
    "    legend = fig.legend(\n",
    "        entries.values(), entries.keys(),\n",
    "        loc='lower center', bbox_to_anchor=(0.5, 0),\n",
    "        ncol=4,\n",
    "        fontsize=11,\n",
    "        title='Contribution', #title='Life-Cycle Phase',\n",
    "        title_fontsize=12\n",
    "    )\n",
    "\n",
    "    # Set tight layout while keeping legend in the screen\n",
    "    bbox = legend.get_window_extent(fig.canvas.get_renderer()).transformed(fig.transFigure.inverted())\n",
    "    fig.tight_layout(rect=(0, bbox.y1, 1, 1), h_pad=0.5, w_pad=0.5)\n",
    "    \n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create process from scenario (previously calculated)\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is1medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "process.compute()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_data_vector_outputs_scenario_2 = process.data['vector_outputs']\n",
    "process_data_float_inputs_scenario_2 = process.data['float_inputs']\n",
    "process_data_climate_scenario_2 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_2 = process.data['lca_outputs']\n",
    "lca_outputs_scenario_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create process from scenario (previously calculated)\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is2medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "process.compute()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_data_vector_outputs_scenario_3 = process.data['vector_outputs']\n",
    "process_data_float_inputs_scenario_3 = process.data['float_inputs']\n",
    "process_data_climate_scenario_3 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_3 = process.data['lca_outputs']\n",
    "lca_outputs_scenario_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create process from scenario (previously calculated)\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is3medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "process.compute()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data_vector_outputs_scenario_4 = process.data['vector_outputs']\n",
    "process_data_float_inputs_scenario_4 = process.data['float_inputs']\n",
    "process_data_climate_scenario_4 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_4 = process.data['lca_outputs']\n",
    "lca_outputs_scenario_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing - From midpoints to endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all endpoints methods\n",
    "methods = [m for m in agb.findMethods('', mainCat='ReCiPe 2016 v1.03, endpoint (H)') if 'total' not in m[1]]\n",
    "methods_custom = [m for m in agb.findMethods('', mainCat='Custom methods') if 'total' not in m[1]]\n",
    "\n",
    "methods_ecosystem = [m for m in methods + methods_custom if 'ecosystem quality' in m[1]]\n",
    "methods_human_health = [m for m in methods + methods_custom if 'human health' in m[1]]\n",
    "methods_resources = [m for m in methods + methods_custom if 'natural resources' in m[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove duplicate methods (i.e. ReCiPe methods which are replaced by a custom method, if both are defined in the configuration file)\n",
    "methods_dict = {'ecosystem quality': methods_ecosystem, 'human health': methods_human_health, 'natural resources': methods_resources}\n",
    "\n",
    "for name, methods_list in methods_dict.items():\n",
    "    methods_to_remove = []\n",
    "    for m in methods_list:\n",
    "        if m[0] == 'Custom methods':\n",
    "            methods_to_remove.append(('ReCiPe 2016 v1.03, endpoint (H)', name, m[2]))\n",
    "    methods_dict[name] = [m for m in methods_list if m not in methods_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add original LCIA methods for climate change to get difference involved by non-CO2\n",
    "# This is more convenient than splitting the results by 'phase' but will require post-processing by hand\n",
    "methods_dict['ecosystem quality'].append(('ReCiPe 2016 v1.03, endpoint (H)', 'ecosystem quality', 'climate change: freshwater ecosystems'))\n",
    "methods_dict['ecosystem quality'].append(('ReCiPe 2016 v1.03, endpoint (H)', 'ecosystem quality', 'climate change: terrestrial ecosystems'))\n",
    "methods_dict['human health'].append(('ReCiPe 2016 v1.03, endpoint (H)', 'human health', 'climate change: human health'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create function to get the data for each scenario\n",
    "def get_scenario_data(scenario, year):\n",
    "    scenario_data_vector = globals()[f'process_data_vector_outputs_scenario_{scenario}']\n",
    "    #scenario_data_fleet = globals()[f'process_data_fleet_model_df_scenario_{scenario}']\n",
    "    scenario_data_float = globals()[f'process_data_float_inputs_scenario_{scenario}']\n",
    "    scenario_data_climate = globals()[f'process_data_climate_scenario_{scenario}']\n",
    "\n",
    "    # !! Make sure all parameters are provided. If a parameter is missing, its default value (1.0) will be applied, so the results will be wrong !!\n",
    "    params_dict = dict(\n",
    "        model=\"remind\",\n",
    "        pathway=\"SSP2_Base\",\n",
    "        rpk_long_range=scenario_data_vector['rpk_long_range'][year],\n",
    "        rpk_medium_range=scenario_data_vector['rpk_medium_range'][year],\n",
    "        rpk_short_range=scenario_data_vector['rpk_short_range'][year],\n",
    "        #aircraft_production_long_range=scenario_data_fleet['Long Range: Aircraft Production'][year],\n",
    "        #aircraft_production_medium_range=scenario_data_fleet['Medium Range: Aircraft Production'][year],\n",
    "        #aircraft_production_short_range=scenario_data_fleet['Short Range: Aircraft Production'][year],\n",
    "        energy_consumption_kerosene=scenario_data_vector['energy_consumption_kerosene'][year],\n",
    "        energy_consumption_biofuel=scenario_data_vector['energy_consumption_biofuel'][year],\n",
    "        energy_consumption_electrofuel=scenario_data_vector['energy_consumption_electrofuel'][year],\n",
    "        energy_consumption_hydrogen=scenario_data_vector['energy_consumption_hydrogen'][year],\n",
    "        lhv_kerosene=scenario_data_float['lhv_kerosene'],\n",
    "        lhv_biofuel=scenario_data_float['lhv_biofuel'],\n",
    "        lhv_electrofuel=scenario_data_float['lhv_electrofuel'],\n",
    "        lhv_hydrogen=scenario_data_float['lhv_hydrogen'],\n",
    "        emission_index_nox_kerosene=scenario_data_vector['emission_index_nox_kerosene'][year],\n",
    "        emission_index_sulfur_kerosene=scenario_data_float['emission_index_sulfur_kerosene'],\n",
    "        #emission_index_h2o_kerosene=scenario_data_float['emission_index_h2o_kerosene'],\n",
    "        emission_index_soot_kerosene=scenario_data_vector['emission_index_soot_kerosene'][year],\n",
    "        emission_index_nox_biofuel=scenario_data_vector['emission_index_nox_biofuel'][year],\n",
    "        emission_index_sulfur_biofuel=scenario_data_float['emission_index_sulfur_biofuel'],\n",
    "        #emission_index_h2o_biofuel=scenario_data_float['emission_index_h2o_biofuel'],\n",
    "        emission_index_soot_biofuel=scenario_data_vector['emission_index_soot_biofuel'][year],\n",
    "        emission_index_nox_electrofuel=scenario_data_vector['emission_index_nox_electrofuel'][year],\n",
    "        emission_index_sulfur_electrofuel=scenario_data_float['emission_index_sulfur_electrofuel'],\n",
    "        #emission_index_h2o_electrofuel=scenario_data_float['emission_index_h2o_electrofuel'],\n",
    "        emission_index_soot_electrofuel=scenario_data_vector['emission_index_soot_electrofuel'][year],\n",
    "        emission_index_nox_hydrogen=scenario_data_vector['emission_index_nox_hydrogen'][year],\n",
    "        total_aircraft_distance=scenario_data_climate['total_aircraft_distance'][year],\n",
    "        fuel_effect_correction_contrails=scenario_data_vector['fuel_effect_correction_contrails'][year],\n",
    "        #load_factor_photovoltaic=1.0,\n",
    "        elec_solar_share=1.0,\n",
    "        year=year\n",
    "    )\n",
    "    \n",
    "    # Check if all parameters are provided\n",
    "    missing_keys = set(agb.params.all_params().keys()) - set(params_dict.keys())\n",
    "    extra_keys = set(agb.params.all_params().keys()) - set(params_dict.keys())\n",
    "    \n",
    "    # Raise errors for missing or extra keys\n",
    "    if missing_keys:\n",
    "        raise KeyError(f\"Parameters are missing: {missing_keys}\")\n",
    "    if extra_keys:\n",
    "        raise KeyError(f\"Two many parameters: {extra_keys}\")\n",
    "    \n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "year=2050  # In what year\n",
    "scenario_numbers = [1, 2, 3, 4]  # Which scenarios\n",
    "\n",
    "# Initialize dictionaries to hold dataframes for each method\n",
    "dfs = {}\n",
    "\n",
    "# This part is not computationnaly efficient and shoud be improved in the future...\n",
    "for method_name, method in methods_dict.items():\n",
    "    df = pd.DataFrame()\n",
    "    for scenario in scenario_numbers:\n",
    "        params_dict = get_scenario_data(scenario, year)\n",
    "\n",
    "        res = agb.compute_impacts(\n",
    "            process.models['life_cycle_assessment'].model,\n",
    "            method,\n",
    "            **params_dict,\n",
    "        )\n",
    "\n",
    "        # Rename the index for the current result\n",
    "        res = res.rename(index={'model': f'scenario {scenario}'})\n",
    "        \n",
    "        # Concatenate the result to the DataFrame\n",
    "        df = pd.concat([df, res], axis=0, ignore_index=False)\n",
    "    \n",
    "    # Normalize by the values of scenario 1\n",
    "    #scenario_1_values = df.loc[df.index == 'scenario 1']\n",
    "    #df = df.divide(scenario_1_values.values.sum())\n",
    "    \n",
    "    # Store the dataframe in the dictionary\n",
    "    dfs[method_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to excel file\n",
    "for method_name in methods_dict.keys():\n",
    "    dfs[method_name].to_excel(f'tsas_endpoints_contributions_{method_name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the xlsx file at your wish for better plots, e.g. by merging low impact categories together and renaming the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reimport the data\n",
    "dfs = {method_name: pd.read_excel(f'tsas_endpoints_contributions_{method_name}.xlsx', index_col=0) for method_name in methods_dict.keys()}\n",
    "combined_df = pd.concat(dfs, names=['Method', 'Scenario'])#.reset_index()#(level=0)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Set up three subplots (one for each endpoint)\n",
    "clusters = combined_df.index.levels[0]  \n",
    "inter_graph = 0\n",
    "maxi = np.max(np.sum(combined_df, axis=1))\n",
    "total_width = len(combined_df)+inter_graph*(len(clusters)-1)\n",
    "fig = plt.figure(figsize=(total_width,6))\n",
    "\n",
    "# Plot properties\n",
    "gridspec.GridSpec(1, total_width)\n",
    "axes=[]\n",
    "palette = sns.color_palette(\"tab10\")\n",
    "#palette.insert(1, palette[1])  # Duplicate color for second position (climate change CO2) for third position (climate change Non-CO2)\n",
    "#hatches = [''] * len(combined_df.index)\n",
    "#hatches[2] = '//'\n",
    "\n",
    "ax_position = 0\n",
    "for cluster in clusters:\n",
    "    subset = combined_df.loc[cluster]\n",
    "    ax = subset.plot(kind=\"bar\", stacked=True, width=0.8, ax=plt.subplot2grid((1,total_width), (0,ax_position), colspan=len(subset.index)), color=palette, alpha=0.8, edgecolor='0.2')\n",
    "    axes.append(ax)\n",
    "    ax.set_title(cluster.title(), fontsize=15)\n",
    "    ax.set_xlabel(\"\")\n",
    "    #ax.set_ylim(0,maxi*1.1)\n",
    "    ax_position += len(subset.index)+inter_graph\n",
    "    ax.tick_params(axis='x', rotation=0, labelsize=11)\n",
    "    \n",
    "    tick_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    wrapped_labels = [\n",
    "        '\\n('.join([label.split('(')[0], label.split('(')[1]]) if '(' in label else label\n",
    "        for label in tick_labels\n",
    "    ]\n",
    "    ax.set_xticklabels(wrapped_labels)\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Apply hatches to the specific segment of the stacks\n",
    "    #for bar_group, hatch_pattern in zip(ax.containers, hatches[:len(subset.columns)]):\n",
    "    #    for bar in bar_group:\n",
    "    #        bar.set_hatch(hatch_pattern)\n",
    "\n",
    "for i in range(0,len(clusters)):\n",
    "    axes[i].legend().set_visible(False)\n",
    "for i in range(1,len(clusters)-1):\n",
    "    axes[i].set_yticklabels(\"\")\n",
    "axes[-1].yaxis.tick_right()\n",
    "axes[-1].tick_params(axis='y', labelsize=13)\n",
    "axes[0].tick_params(axis='y', labelsize=13)\n",
    "axes[0].set_ylabel(\"Impacts relative to IS0\", fontsize=15)\n",
    "\n",
    "# Collect legend labels from all plots.\n",
    "entries = collections.OrderedDict()\n",
    "for ax in axes:\n",
    "    for handle, label in zip(*axes[0].get_legend_handles_labels()):\n",
    "        label_name = label.replace('_', ' ').title()\n",
    "        entries[label_name] = handle\n",
    "legend = fig.legend(\n",
    "    entries.values(), entries.keys(),\n",
    "    loc='lower center', bbox_to_anchor=(0.5, 0),\n",
    "    ncol=2,\n",
    "    fontsize=13,\n",
    "    title='Midpoint Category',\n",
    "    title_fontsize=14\n",
    ")\n",
    "\n",
    "# Set tight layout while keeping legend in the screen\n",
    "bbox = legend.get_window_extent(fig.canvas.get_renderer()).transformed(fig.transFigure.inverted())\n",
    "fig.tight_layout(rect=(0, bbox.y1, 1, 1), h_pad=0.5, w_pad=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
