{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677aa44f9870d6e6",
   "metadata": {},
   "source": [
    "# Life Cycle Assessment - TSAS scenarios\n",
    "\n",
    "> **⚠ This notebook has been developed with the AeroMAPS version v0.7.1-beta for obtaining the paper results. However, this notebook has been or could be modified in order to be executable with the latest versions of AeroMAPS, which sometimes leads to different results compared to the ones from the paper, due to some models' modifications. In order to retrieve the results of the paper, one can use the v0.7.1-beta version associated with the original notebook.**\n",
    "\n",
    "The LCA module performs an environmental assessment of the scenarios using data from both AeroMAPS (e.g., fuel combustion emission factors) and the ecoinvent database (for background processes such as electricity generation). In this case study, the environmental profiles of the various fuel production pathways (biofuels and electrofuels) are entirely based on *ecoinvent* data (completed by *premise*) rather than AeroMAPS models. In particular, the some environmental characteristics of the fuel pathways provided in the `energy_inputs.yaml` files are overrode by ecoinvent data in the LCA module (for example the mean CO2 emission factor). While this approach ensures broader coverage of environmental processes, it may also lead to results that are not fully consistent with those generated by AeroMAPS’ core impact models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106ca75e7de7e4",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "First, the user has to load the framework and generate a process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32388e0ec071a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import libraries ---\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import brightway2 as bw\n",
    "import lca_algebraic as agb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import math\n",
    "import collections\n",
    "import time\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "\n",
    "# --- Aeromaps models and processes ---\n",
    "from aeromaps import create_process\n",
    "from aeromaps.core.models import (\n",
    "    models_traffic,\n",
    "    models_efficiency_top_down_interp,\n",
    "    models_energy_with_fuel_effect,\n",
    "    models_offset,\n",
    "    models_climate_fair,\n",
    "    models_energy_cost,\n",
    "    models_operation_cost_top_down,\n",
    "    models_abatements_cost_simplified,\n",
    ")\n",
    "from aeromaps.models.impacts.life_cycle_assessment.life_cycle_assessment import LifeCycleAssessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c0859a9c00e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set AeroMAPS models for this simulation ---\n",
    "# Note: first call to LCA module takes a dozen minutes depending on CPU, as it will install ecoinvent/premise databases (unless previsouly installed)\n",
    "# and parametrize the LCA model declared in LCA configuration file (each time the kernel is restarted).\n",
    "models = {\n",
    "    \"models_traffic\": models_traffic,\n",
    "    \"models_efficiency_top_down_interp\": models_efficiency_top_down_interp,\n",
    "    \"models_energy_with_fuel_effect\": models_energy_with_fuel_effect,\n",
    "    \"models_offset\": models_offset,\n",
    "    \"models_climate_fair\": models_climate_fair,\n",
    "    \"models_energy_cost\": models_energy_cost,\n",
    "    \"models_operation_cost_top_down\": models_operation_cost_top_down,\n",
    "    \"models_abatements_cost_simplified\": models_abatements_cost_simplified,\n",
    "    \"life_cycle_assessment\": LifeCycleAssessment(\n",
    "        configuration_file=\"./data/lca_data/configuration_file_lca_tsas.yaml\", split_by=\"phase\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d49f4f4986a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For check only: check which LCA databases were installed\n",
    "list(bw.databases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637e4409ec920e",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30b598cbceb42f",
   "metadata": {},
   "source": [
    "### a) Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5355e0d2fac69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS0 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is0medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a3e03f8ee75",
   "metadata": {},
   "source": [
    "### b) Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473da9bdc434b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ff4b8fece7d4a",
   "metadata": {},
   "source": [
    "### c) Results and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1a0cc44be2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "process_data_vector_outputs_scenario_1 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_1 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_1 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_1 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0ca37de6a661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_evolution_subplots(xarray_data):\n",
    "    \"\"\"\n",
    "    Plots a stacked evolution of the LCA results provided as an xarray\n",
    "    \"\"\"\n",
    "\n",
    "    df = xarray_data.to_dataframe().reset_index()\n",
    "\n",
    "    # Set the desired columns as a MultiIndex\n",
    "    df = df.set_index([\"impacts\", \"axis\", \"year\"])\n",
    "\n",
    "    # Pivot the DataFrame to have years as columns\n",
    "    df = df.pivot_table(values=\"lca\", index=[\"impacts\", \"axis\"], columns=\"year\")\n",
    "\n",
    "    # Remove phases containing 'sum'\n",
    "    df_filtered = df[~df.index.get_level_values(\"axis\").str.contains(\"sum\")]\n",
    "    df_filtered = df_filtered[\n",
    "        ~df_filtered.index.get_level_values(\"axis\").str.contains(\"_other_\")\n",
    "    ]  # make sure it is equal to zero before deleting\n",
    "\n",
    "    methods = df_filtered.index.get_level_values(\"impacts\").unique()  # [:9]\n",
    "    years = df_filtered.columns\n",
    "\n",
    "    # Determine the number of rows and columns for the subplots\n",
    "    n_methods = len(methods)\n",
    "    n_cols = 3  # 2 if n_methods % 2 == 0 else 3\n",
    "    n_rows = math.ceil(n_methods / n_cols)\n",
    "\n",
    "    # Use seaborn color palette for better aesthetics\n",
    "    palette = sns.color_palette(\"Set2\", len(df_filtered.index.levels[1]))\n",
    "    # palette = sns.color_palette(\"Paired\", len(df_filtered.index.levels[1]))\n",
    "    palette_dict = {\n",
    "        \"aircraft_production\": (palette[3], \"\"),\n",
    "        \"airport\": (palette[1], \"\"),\n",
    "        \"kerosene_production\": (palette[2], \"\"),\n",
    "        \"biofuel_production\": (palette[5], \"\"),\n",
    "        \"e_fuel_production\": (palette[8], \"\"),\n",
    "        \"hydrogen_production\": (palette[6], \"\"),\n",
    "        \"CO2 from combustion\": (palette[7], \"\"),\n",
    "        \"Non-CO2 from combustion\": (\"0.8\", \"//\"),\n",
    "        #'Production Electrofuel\\n(Electrolysis)': ('0.8', '\\\\'),\n",
    "        #'production_kerosene': (palette[8], ''),\n",
    "    }\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 4), constrained_layout=False)\n",
    "    axes = axes.flatten()  # Flatten the array of axes for easy iteration\n",
    "\n",
    "    for i, method in enumerate(methods):\n",
    "        df_method = df_filtered.xs(method, level=\"impacts\")\n",
    "        df_method.index = df_method.index.str.replace(\"_other_\", \"Others\")\n",
    "\n",
    "        # Group CO2 emissions together\n",
    "        co2_rows = df_method.index.str.startswith(\"CO2\")\n",
    "        co2_aggregated = df_method[co2_rows].sum()\n",
    "        co2_aggregated.name = \"CO2 from combustion\"\n",
    "        df_method = pd.concat(\n",
    "            [df_method[~co2_rows], co2_aggregated.to_frame().T], ignore_index=False\n",
    "        )\n",
    "\n",
    "        # Group non-CO2 emissions together\n",
    "        nonco2_rows = df_method.index.str.startswith(\"non_CO2\")\n",
    "        nonco2_aggregated = df_method[nonco2_rows].sum()\n",
    "        nonco2_aggregated.name = \"Non-CO2 from combustion\"\n",
    "        df_method = pd.concat(\n",
    "            [df_method[~nonco2_rows], nonco2_aggregated.to_frame().T], ignore_index=False\n",
    "        )\n",
    "\n",
    "        # Remove elements with no contribution to score\n",
    "        df_method = df_method.loc[~(df_method.eq(0).all(axis=1))]\n",
    "\n",
    "        # Plot stacked area chart with custom colors\n",
    "        # stacks = axes[i].stackplot(years, df_method, labels=df_method.index, alpha=0.8, colors=palette)\n",
    "        colors = [palette_dict[key][0] for key in df_method.index]\n",
    "        stacks = axes[i].stackplot(\n",
    "            years, df_method, labels=df_method.index, alpha=0.8, colors=colors, linewidth=0.2\n",
    "        )\n",
    "\n",
    "        # Customize the subplot\n",
    "        name = method[2]\n",
    "        # name = name.replace('- ', '\\n').replace('(', '\\n(')\n",
    "        name = name.replace(\"(with non-CO2)\", \"\")\n",
    "        name = name.replace(\"total\", \"\")\n",
    "        name = name.split(\"- \")[0]\n",
    "        name = name.replace(\":\", \"\\n\")\n",
    "        name = \"\".join([a if a.isupper() else b for a, b in zip(name, name.title())])\n",
    "\n",
    "        unit = bw.Method(method).metadata.get(\"unit\")\n",
    "        unit = unit.replace(\"]\", \"\")\n",
    "        unit = unit.replace(\"m2*a crop-Eq\", r\"m$^2\\times$yr annual crop land\")\n",
    "        unit = unit.replace(\"-Eq\", \"-eq\")\n",
    "        unit = unit.replace(\"CO2\", r\"CO$_2$\")\n",
    "\n",
    "        axes[i].set_title(name, fontsize=12)\n",
    "        axes[i].set_xlabel(\"Year\")\n",
    "        axes[i].set_ylabel(unit)\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_axisbelow(True)\n",
    "        axes[i].ticklabel_format(axis=\"y\", scilimits=(0, 4))\n",
    "        axes[i].set_facecolor(\"white\")\n",
    "\n",
    "        # Set hatches pattern\n",
    "        hatches = [palette_dict[key][1] for key in df_method.index]\n",
    "        for stack, hatch, values in zip(stacks, hatches, df_method.values):\n",
    "            if np.any(values != 0):  # Check if the layer has non-zero values\n",
    "                stack.set_edgecolor(\"0.1\")\n",
    "            # stack.set_edgecolor(color)\n",
    "            if hatch:\n",
    "                stack.set_hatch(hatch)\n",
    "\n",
    "    # Collect legend labels from all plots.\n",
    "    all_handles = []\n",
    "    all_labels = []\n",
    "    for ax in axes:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        all_handles.extend(handles)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    entries = collections.OrderedDict()\n",
    "    for ax in axes.flatten():\n",
    "        for handle, label in zip(all_handles, all_labels):\n",
    "            # if 'biofuel' in label or 'electrofuel' in label:\n",
    "            #    continue\n",
    "            if label == \"Others\":\n",
    "                continue\n",
    "            if \"CO2\" in label:\n",
    "                label_name = label.replace(\"CO2\", r\"CO$_2$\")\n",
    "            elif \"e_fuel\" in label:\n",
    "                label_name = label.replace(\"e_fuel\", \"E-Fuel\").replace(\"_\", \" \").title()\n",
    "            else:\n",
    "                label_name = label.replace(\"_\", \" \").title()\n",
    "            entries[label_name] = handle\n",
    "    legend = fig.legend(\n",
    "        entries.values(),\n",
    "        entries.keys(),\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, 0),\n",
    "        ncol=4,\n",
    "        fontsize=11,\n",
    "        title=\"Contribution\",  # title='Life-Cycle Phase',\n",
    "        title_fontsize=12,\n",
    "    )\n",
    "\n",
    "    # Set tight layout while keeping legend in the screen\n",
    "    bbox = legend.get_window_extent(fig.canvas.get_renderer()).transformed(\n",
    "        fig.transFigure.inverted()\n",
    "    )\n",
    "    fig.tight_layout(rect=(0, bbox.y1, 1, 1), h_pad=0.5, w_pad=0.5)\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464b0ae05a38188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e532f58289c0f3",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cf8e8c002b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS1 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is1medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bed341d7e317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e2007cfb03904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_2 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_2 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_2 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_2 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cfd1395e097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b0d9bede71494",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61c29f0415f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS2 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is2medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616728573676ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73231a41858dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_3 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_3 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_3 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_3 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922edf84677882e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b654eb4a0d63c",
   "metadata": {},
   "source": [
    "## Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a7ec831bf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS3 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is3medium.json\",\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d4774aea8e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f982034a2252887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_4 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_4 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_4 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_4 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3193788d0c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6e29acd042ad2",
   "metadata": {},
   "source": [
    "# Postprocessing - From midpoints to endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffa15a4dc1442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all endpoints methods\n",
    "methods = [\n",
    "    m for m in agb.findMethods(\"\", mainCat=\"ReCiPe 2016 v1.03, endpoint (H)\") if \"total\" not in m[1]\n",
    "]\n",
    "methods_custom = [m for m in agb.findMethods(\"\", mainCat=\"Custom methods\") if \"total\" not in m[1]]\n",
    "\n",
    "methods_ecosystem = [m for m in methods + methods_custom if \"ecosystem quality\" in m[1]]\n",
    "methods_human_health = [m for m in methods + methods_custom if \"human health\" in m[1]]\n",
    "methods_resources = [m for m in methods + methods_custom if \"natural resources\" in m[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87968982d170dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate methods (i.e. ReCiPe methods which are replaced by a custom method, if both are defined in the configuration file)\n",
    "methods_dict = {\n",
    "    \"ecosystem quality\": methods_ecosystem,\n",
    "    \"human health\": methods_human_health,\n",
    "    \"natural resources\": methods_resources,\n",
    "}\n",
    "\n",
    "for name, methods_list in methods_dict.items():\n",
    "    methods_to_remove = []\n",
    "    for m in methods_list:\n",
    "        if m[0] == \"Custom methods\":\n",
    "            methods_to_remove.append((\"ReCiPe 2016 v1.03, endpoint (H)\", name, m[2]))\n",
    "    methods_dict[name] = [m for m in methods_list if m not in methods_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448a26c09d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add original LCIA methods for climate change to get difference involved by non-CO2\n",
    "# This is more convenient than splitting the results by 'phase' but will require post-processing by hand\n",
    "methods_dict[\"ecosystem quality\"].append(\n",
    "    (\n",
    "        \"ReCiPe 2016 v1.03, endpoint (H)\",\n",
    "        \"ecosystem quality\",\n",
    "        \"climate change: freshwater ecosystems\",\n",
    "    )\n",
    ")\n",
    "methods_dict[\"ecosystem quality\"].append(\n",
    "    (\n",
    "        \"ReCiPe 2016 v1.03, endpoint (H)\",\n",
    "        \"ecosystem quality\",\n",
    "        \"climate change: terrestrial ecosystems\",\n",
    "    )\n",
    ")\n",
    "methods_dict[\"human health\"].append(\n",
    "    (\"ReCiPe 2016 v1.03, endpoint (H)\", \"human health\", \"climate change: human health\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39456433f25bea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get the data for each scenario\n",
    "def get_scenario_data(scenario, year):\n",
    "    scenario_data_vector = globals()[f\"process_data_vector_outputs_scenario_{scenario}\"]\n",
    "    # scenario_data_fleet = globals()[f'process_data_fleet_model_df_scenario_{scenario}']\n",
    "    scenario_data_float = globals()[f\"process_data_float_inputs_scenario_{scenario}\"]\n",
    "    scenario_data_climate = globals()[f\"process_data_climate_scenario_{scenario}\"]\n",
    "\n",
    "    # !! Make sure all parameters are provided. If a parameter is missing, its default value (1.0) will be applied, so the results will be wrong !!\n",
    "    params_dict = dict(\n",
    "        model=\"remind\",\n",
    "        pathway=\"SSP2_Base\",\n",
    "        rpk_long_range=scenario_data_vector[\"rpk_long_range\"][year],\n",
    "        rpk_medium_range=scenario_data_vector[\"rpk_medium_range\"][year],\n",
    "        rpk_short_range=scenario_data_vector[\"rpk_short_range\"][year],\n",
    "        # aircraft_production_long_range=scenario_data_fleet['Long Range: Aircraft Production'][year],\n",
    "        # aircraft_production_medium_range=scenario_data_fleet['Medium Range: Aircraft Production'][year],\n",
    "        # aircraft_production_short_range=scenario_data_fleet['Short Range: Aircraft Production'][year],\n",
    "        fossil_kerosene_mass_consumption=scenario_data_vector[\"fossil_kerosene_mass_consumption\"][\n",
    "            year\n",
    "        ],\n",
    "        generic_biofuel_mass_consumption=scenario_data_vector[\"generic_biofuel_mass_consumption\"][\n",
    "            year\n",
    "        ]\n",
    "        if \"generic_biofuel_mass_consumption\" in scenario_data_vector\n",
    "        else 0.0,\n",
    "        electrofuel_mass_consumption=scenario_data_vector[\"electrofuel_mass_consumption\"][year]\n",
    "        if \"electrofuel_mass_consumption\" in scenario_data_vector\n",
    "        else 0.0,\n",
    "        hydrogen_electrolysis_mass_consumption=scenario_data_vector[\n",
    "            \"hydrogen_electrolysis_mass_consumption\"\n",
    "        ][year]\n",
    "        if \"hydrogen_electrolysis_mass_consumption\" in scenario_data_vector\n",
    "        else 0.0,\n",
    "        fossil_kerosene_lhv=scenario_data_float[\"fossil_kerosene_lhv\"],\n",
    "        generic_biofuel_lhv=scenario_data_float[\"generic_biofuel_lhv\"],\n",
    "        electrofuel_lhv=scenario_data_float[\"electrofuel_lhv\"],\n",
    "        # lhv_hydrogen=scenario_data_float['lhv_hydrogen'],\n",
    "        fossil_kerosene_emission_index_nox=scenario_data_float[\n",
    "            \"fossil_kerosene_emission_index_nox\"\n",
    "        ],\n",
    "        fossil_kerosene_emission_index_sulfur=scenario_data_float[\n",
    "            \"fossil_kerosene_emission_index_sulfur\"\n",
    "        ],\n",
    "        fossil_kerosene_emission_index_soot=scenario_data_float[\n",
    "            \"fossil_kerosene_emission_index_soot\"\n",
    "        ],\n",
    "        generic_biofuel_emission_index_nox=scenario_data_float[\n",
    "            \"generic_biofuel_emission_index_nox\"\n",
    "        ],\n",
    "        generic_biofuel_emission_index_sulfur=scenario_data_float[\n",
    "            \"generic_biofuel_emission_index_sulfur\"\n",
    "        ],\n",
    "        generic_biofuel_emission_index_soot=scenario_data_float[\n",
    "            \"generic_biofuel_emission_index_soot\"\n",
    "        ],\n",
    "        electrofuel_emission_index_nox=scenario_data_float[\"electrofuel_emission_index_nox\"],\n",
    "        electrofuel_emission_index_sulfur=scenario_data_float[\"electrofuel_emission_index_sulfur\"],\n",
    "        electrofuel_emission_index_soot=scenario_data_float[\"electrofuel_emission_index_soot\"],\n",
    "        hydrogen_electrolysis_emission_index_nox=scenario_data_float[\n",
    "            \"hydrogen_electrolysis_emission_index_nox\"\n",
    "        ],\n",
    "        total_aircraft_distance=scenario_data_climate[\"total_aircraft_distance\"][year],\n",
    "        fuel_effect_correction_contrails=scenario_data_vector[\"fuel_effect_correction_contrails\"][\n",
    "            year\n",
    "        ],\n",
    "        # load_factor_photovoltaic=1.0,\n",
    "        elec_solar_share=1.0,\n",
    "        year=year,\n",
    "    )\n",
    "\n",
    "    # Check if all parameters are provided\n",
    "    missing_keys = set(agb.params.all_params().keys()) - set(params_dict.keys())\n",
    "    extra_keys = set(agb.params.all_params().keys()) - set(params_dict.keys())\n",
    "\n",
    "    # Raise errors for missing or extra keys\n",
    "    if missing_keys:\n",
    "        raise KeyError(f\"Parameters are missing: {missing_keys}\")\n",
    "    if extra_keys:\n",
    "        raise KeyError(f\"Two many parameters: {extra_keys}\")\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e453fabfd1d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "year = 2050  # In what year\n",
    "scenario_numbers = [1, 2, 3, 4]  # Which scenarios\n",
    "\n",
    "# Initialize dictionaries to hold dataframes for each method\n",
    "dfs = {}\n",
    "\n",
    "# This part is not computationnaly efficient and shoud be improved in the future...\n",
    "for method_name, method in methods_dict.items():\n",
    "    df = pd.DataFrame()\n",
    "    for scenario in scenario_numbers:\n",
    "        params_dict = get_scenario_data(scenario, year)\n",
    "\n",
    "        res = agb.compute_impacts(\n",
    "            process.models[\"life_cycle_assessment\"].model,\n",
    "            method,\n",
    "            **params_dict,\n",
    "        )\n",
    "\n",
    "        # Rename the index for the current result\n",
    "        res = res.rename(index={\"model\": f\"scenario {scenario}\"})\n",
    "\n",
    "        # Concatenate the result to the DataFrame\n",
    "        df = pd.concat([df, res], axis=0, ignore_index=False)\n",
    "\n",
    "    # Normalize by the values of scenario 1\n",
    "    # scenario_1_values = df.loc[df.index == 'scenario 1']\n",
    "    # df = df.divide(scenario_1_values.values.sum())\n",
    "\n",
    "    # Store the dataframe in the dictionary\n",
    "    dfs[method_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd37d8d58e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to excel file\n",
    "for method_name in methods_dict.keys():\n",
    "    dfs[method_name].to_excel(f\"tsas_endpoints_contributions_{method_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3726b599ecde9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the xlsx file at your wish for better plots, e.g. by merging low impact categories together and renaming the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b0141e8ce8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimport the data\n",
    "dfs = {\n",
    "    method_name: pd.read_excel(f\"tsas_endpoints_contributions_{method_name}.xlsx\", index_col=0)\n",
    "    for method_name in methods_dict.keys()\n",
    "}\n",
    "combined_df = pd.concat(dfs, names=[\"Method\", \"Scenario\"])  # .reset_index()#(level=0)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e8609c56d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Set up three subplots (one for each endpoint)\n",
    "clusters = combined_df.index.levels[0]\n",
    "inter_graph = 0\n",
    "maxi = np.max(np.sum(combined_df, axis=1))\n",
    "total_width = len(combined_df) + inter_graph * (len(clusters) - 1)\n",
    "fig = plt.figure(figsize=(total_width, 6))\n",
    "\n",
    "# Plot properties\n",
    "gridspec.GridSpec(1, total_width)\n",
    "axes = []\n",
    "palette = sns.color_palette(\"tab10\")\n",
    "# palette.insert(1, palette[1])  # Duplicate color for second position (climate change CO2) for third position (climate change Non-CO2)\n",
    "# hatches = [''] * len(combined_df.index)\n",
    "# hatches[2] = '//'\n",
    "\n",
    "ax_position = 0\n",
    "for cluster in clusters:\n",
    "    subset = combined_df.loc[cluster]\n",
    "    ax = subset.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        width=0.8,\n",
    "        ax=plt.subplot2grid((1, total_width), (0, ax_position), colspan=len(subset.index)),\n",
    "        color=palette,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"0.2\",\n",
    "    )\n",
    "    axes.append(ax)\n",
    "    ax.set_title(cluster.title(), fontsize=15)\n",
    "    ax.set_xlabel(\"\")\n",
    "    # ax.set_ylim(0,maxi*1.1)\n",
    "    ax_position += len(subset.index) + inter_graph\n",
    "    ax.tick_params(axis=\"x\", rotation=0, labelsize=11)\n",
    "\n",
    "    tick_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    wrapped_labels = [\n",
    "        \"\\n(\".join([label.split(\"(\")[0], label.split(\"(\")[1]]) if \"(\" in label else label\n",
    "        for label in tick_labels\n",
    "    ]\n",
    "    ax.set_xticklabels(wrapped_labels)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Apply hatches to the specific segment of the stacks\n",
    "    # for bar_group, hatch_pattern in zip(ax.containers, hatches[:len(subset.columns)]):\n",
    "    #    for bar in bar_group:\n",
    "    #        bar.set_hatch(hatch_pattern)\n",
    "\n",
    "for i in range(0, len(clusters)):\n",
    "    axes[i].legend().set_visible(False)\n",
    "for i in range(1, len(clusters) - 1):\n",
    "    axes[i].set_yticklabels(\"\")\n",
    "axes[-1].yaxis.tick_right()\n",
    "axes[-1].tick_params(axis=\"y\", labelsize=13)\n",
    "axes[0].tick_params(axis=\"y\", labelsize=13)\n",
    "axes[0].set_ylabel(\"Impacts relative to IS0\", fontsize=15)\n",
    "\n",
    "# Collect legend labels from all plots.\n",
    "entries = collections.OrderedDict()\n",
    "for ax in axes:\n",
    "    for handle, label in zip(*axes[0].get_legend_handles_labels()):\n",
    "        label_name = label.replace(\"_\", \" \").title()\n",
    "        entries[label_name] = handle\n",
    "legend = fig.legend(\n",
    "    entries.values(),\n",
    "    entries.keys(),\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    ncol=2,\n",
    "    fontsize=13,\n",
    "    title=\"Midpoint Category\",\n",
    "    title_fontsize=14,\n",
    ")\n",
    "\n",
    "# Set tight layout while keeping legend in the screen\n",
    "bbox = legend.get_window_extent(fig.canvas.get_renderer()).transformed(fig.transFigure.inverted())\n",
    "fig.tight_layout(rect=(0, bbox.y1, 1, 1), h_pad=0.5, w_pad=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49a27403b0869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
