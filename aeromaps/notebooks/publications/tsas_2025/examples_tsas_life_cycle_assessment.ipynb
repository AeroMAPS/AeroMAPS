{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677aa44f9870d6e6",
   "metadata": {},
   "source": [
    "# Life Cycle Assessment - TSAS scenarios\n",
    "\n",
    "> **⚠ This notebook has been developed with the AeroMAPS version v0.7.1-beta for obtaining the paper results. However, this notebook has been or could be modified in order to be executable with the latest versions of AeroMAPS, which sometimes leads to different results compared to the ones from the paper, due to some models' modifications. In order to retrieve the results of the paper, one can use the v0.7.1-beta version associated with the original notebook.**\n",
    "\n",
    "The LCA module performs an environmental assessment of the scenarios using data from both AeroMAPS (e.g., fuel combustion emission factors) and the ecoinvent database (for background processes such as electricity generation). In this case study, the environmental profiles of the various fuel production pathways (biofuels and electrofuels) are entirely based on *ecoinvent* data (completed by *premise*) rather than AeroMAPS models. In particular, the some environmental characteristics of the fuel pathways provided in the `energy_inputs.yaml` files are overrode by ecoinvent data in the LCA module (for example the mean CO2 emission factor). While this approach ensures broader coverage of environmental processes, it may also lead to results that are not fully consistent with those generated by AeroMAPS’ core impact models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106ca75e7de7e4",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "First, the user has to load the framework and generate a process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32388e0ec071a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import libraries ---\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import brightway2 as bw\n",
    "import lca_algebraic as agb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import math\n",
    "import collections\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(0, './utils/')\n",
    "from plots import plot_stacked_evolution_subplots\n",
    "from aeromaps import create_process\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637e4409ec920e",
   "metadata": {},
   "source": [
    "## Scenario IS0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5355e0d2fac69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set AeroMAPS models and create process for scenario IS0 ---\n",
    "# Note: first call to LCA module takes a dozen minutes depending on CPU, as it will install ecoinvent/premise databases (unless previsouly installed)\n",
    "# and parametrize the LCA model declared in LCA configuration file (each time the kernel is restarted).\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is0medium_lca.yaml\",\n",
    ")\n",
    "\n",
    "# For check only: check which LCA databases were installed\n",
    "list(bw.databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473da9bdc434b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1a0cc44be2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_0 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_0 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_0 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_0 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464b0ae05a38188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e532f58289c0f3",
   "metadata": {},
   "source": [
    "## Scenario IS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cf8e8c002b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS1 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is1medium_lca.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bed341d7e317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e2007cfb03904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_1 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_1 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_1 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_1 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cfd1395e097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b0d9bede71494",
   "metadata": {},
   "source": [
    "## Scenario IS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61c29f0415f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS2 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is2medium_lca.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616728573676ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73231a41858dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_2 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_2 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_2 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_2 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922edf84677882e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b654eb4a0d63c",
   "metadata": {},
   "source": [
    "## Scenario IS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a7ec831bf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create process for scenario IS3 medium ---\n",
    "process = create_process(\n",
    "    configuration_file=\"data/config_files/config_is3medium_lca.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d4774aea8e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run assessment ---\n",
    "start_time = time.time()\n",
    "process.compute()\n",
    "process.write_json()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f982034a2252887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outputs ---\n",
    "process_data_vector_outputs_scenario_3 = process.data[\"vector_outputs\"]\n",
    "process_data_float_inputs_scenario_3 = process.data[\"float_inputs\"]\n",
    "process_data_climate_scenario_3 = process.data[\"climate_outputs\"]\n",
    "lca_outputs_scenario_3 = process.data[\"lca_outputs\"]\n",
    "lca_outputs_scenario_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3193788d0c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot results ---\n",
    "plt.close()\n",
    "plot_stacked_evolution_subplots(lca_outputs_scenario_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6e29acd042ad2",
   "metadata": {},
   "source": [
    "# Postprocessing - From midpoints to endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffa15a4dc1442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all endpoints methods\n",
    "methods = [\n",
    "    m for m in agb.findMethods(\"\", mainCat=\"ReCiPe 2016 v1.03, endpoint (H)\") if \"total\" not in m[1]\n",
    "]\n",
    "methods_custom = [m for m in agb.findMethods(\"\", mainCat=\"Custom methods\") if \"total\" not in m[1]]\n",
    "\n",
    "methods_ecosystem = [m for m in methods + methods_custom if \"ecosystem quality\" in m[1]]\n",
    "methods_human_health = [m for m in methods + methods_custom if \"human health\" in m[1]]\n",
    "methods_resources = [m for m in methods + methods_custom if \"natural resources\" in m[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87968982d170dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate methods (i.e. ReCiPe methods which are replaced by a custom method, if both are defined in the configuration file)\n",
    "methods_dict = {\n",
    "    \"ecosystem quality\": methods_ecosystem,\n",
    "    \"human health\": methods_human_health,\n",
    "    \"natural resources\": methods_resources,\n",
    "}\n",
    "\n",
    "for name, methods_list in methods_dict.items():\n",
    "    methods_to_remove = []\n",
    "    for m in methods_list:\n",
    "        if m[0] == \"Custom methods\":\n",
    "            methods_to_remove.append((\"ReCiPe 2016 v1.03, endpoint (H)\", name, m[2]))\n",
    "    methods_dict[name] = [m for m in methods_list if m not in methods_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448a26c09d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add original LCIA methods for climate change to get difference involved by non-CO2\n",
    "# This is more convenient than splitting the results by 'phase' but will require post-processing by hand\n",
    "methods_dict[\"ecosystem quality\"].append(\n",
    "    (\n",
    "        \"ReCiPe 2016 v1.03, endpoint (H)\",\n",
    "        \"ecosystem quality\",\n",
    "        \"climate change: freshwater ecosystems\",\n",
    "    )\n",
    ")\n",
    "methods_dict[\"ecosystem quality\"].append(\n",
    "    (\n",
    "        \"ReCiPe 2016 v1.03, endpoint (H)\",\n",
    "        \"ecosystem quality\",\n",
    "        \"climate change: terrestrial ecosystems\",\n",
    "    )\n",
    ")\n",
    "methods_dict[\"human health\"].append(\n",
    "    (\"ReCiPe 2016 v1.03, endpoint (H)\", \"human health\", \"climate change: human health\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39456433f25bea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get the data for each scenario\n",
    "def get_scenario_data(scenario, year):\n",
    "    scenario_data_vector = globals()[f\"process_data_vector_outputs_scenario_{scenario}\"]\n",
    "    scenario_data_float = globals()[f\"process_data_float_inputs_scenario_{scenario}\"]\n",
    "    scenario_data_climate = globals()[f\"process_data_climate_scenario_{scenario}\"]\n",
    "\n",
    "    params_dict = dict(\n",
    "        model=\"remind\",\n",
    "        pathway=\"SSP2_NPi\",\n",
    "        rpk_long_range=scenario_data_vector[\"rpk_long_range\"][year],\n",
    "        rpk_medium_range=scenario_data_vector[\"rpk_medium_range\"][year],\n",
    "        rpk_short_range=scenario_data_vector[\"rpk_short_range\"][year],\n",
    "        fossil_kerosene_mass_consumption=scenario_data_vector[\"fossil_kerosene_mass_consumption\"][\n",
    "            year\n",
    "        ],\n",
    "        generic_biofuel_mass_consumption=scenario_data_vector[\"generic_biofuel_mass_consumption\"][\n",
    "            year\n",
    "        ]\n",
    "        if \"generic_biofuel_mass_consumption\" in scenario_data_vector\n",
    "        else 0.0,\n",
    "        electrofuel_mass_consumption=scenario_data_vector[\"electrofuel_mass_consumption\"][year]\n",
    "        if \"electrofuel_mass_consumption\" in scenario_data_vector\n",
    "        else 0.0,\n",
    "        hydrogen_electrolysis_mass_consumption=scenario_data_vector[\n",
    "            \"hydrogen_electrolysis_mass_consumption\"\n",
    "        ][year]\n",
    "        if \"hydrogen_electrolysis_mass_consumption\" in scenario_data_vector\n",
    "        else 0.0,\n",
    "        fossil_kerosene_lhv=scenario_data_float[\"fossil_kerosene_lhv\"],\n",
    "        generic_biofuel_lhv=scenario_data_float[\"generic_biofuel_lhv\"],\n",
    "        electrofuel_lhv=scenario_data_float[\"electrofuel_lhv\"],\n",
    "        fossil_kerosene_emission_index_nox=scenario_data_float[\n",
    "            \"fossil_kerosene_emission_index_nox\"\n",
    "        ],\n",
    "        fossil_kerosene_emission_index_sulfur=scenario_data_float[\n",
    "            \"fossil_kerosene_emission_index_sulfur\"\n",
    "        ],\n",
    "        fossil_kerosene_emission_index_soot=scenario_data_float[\n",
    "            \"fossil_kerosene_emission_index_soot\"\n",
    "        ],\n",
    "        generic_biofuel_emission_index_nox=scenario_data_float[\n",
    "            \"generic_biofuel_emission_index_nox\"\n",
    "        ],\n",
    "        generic_biofuel_emission_index_sulfur=scenario_data_float[\n",
    "            \"generic_biofuel_emission_index_sulfur\"\n",
    "        ],\n",
    "        generic_biofuel_emission_index_soot=scenario_data_float[\n",
    "            \"generic_biofuel_emission_index_soot\"\n",
    "        ],\n",
    "        electrofuel_emission_index_nox=scenario_data_float[\"electrofuel_emission_index_nox\"],\n",
    "        electrofuel_emission_index_sulfur=scenario_data_float[\"electrofuel_emission_index_sulfur\"],\n",
    "        electrofuel_emission_index_soot=scenario_data_float[\"electrofuel_emission_index_soot\"],\n",
    "        hydrogen_electrolysis_emission_index_nox=scenario_data_float[\n",
    "            \"hydrogen_electrolysis_emission_index_nox\"\n",
    "        ],\n",
    "        total_aircraft_distance=scenario_data_climate[\"total_aircraft_distance\"][year],\n",
    "        fuel_effect_correction_contrails=scenario_data_vector[\"fuel_effect_correction_contrails\"][\n",
    "            year\n",
    "        ],\n",
    "        elec_solar_share=1.0,\n",
    "        year=year,\n",
    "    )\n",
    "\n",
    "    # Check if all parameters are provided\n",
    "    missing_keys = set(agb.params.all_params().keys()) - set(params_dict.keys())\n",
    "    extra_keys = set(agb.params.all_params().keys()) - set(params_dict.keys())\n",
    "\n",
    "    # Raise errors for missing or extra keys\n",
    "    if missing_keys:\n",
    "        raise KeyError(f\"Parameters are missing: {missing_keys}\")\n",
    "    if extra_keys:\n",
    "        raise KeyError(f\"Two many parameters: {extra_keys}\")\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e453fabfd1d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "year = 2050  # In what year\n",
    "scenario_numbers = [0, 1, 2, 3]  # Which scenarios (is0 to is3)\n",
    "\n",
    "# Initialize dictionaries to hold dataframes for each method\n",
    "dfs = {}\n",
    "\n",
    "# This part is not computationnaly efficient and shoud be improved in the future...\n",
    "for method_name, method in methods_dict.items():\n",
    "    df = pd.DataFrame()\n",
    "    for scenario in scenario_numbers:\n",
    "        params_dict = get_scenario_data(scenario, year)\n",
    "\n",
    "        res = agb.compute_impacts(\n",
    "            process.models[\"life_cycle_assessment\"].model,\n",
    "            method,\n",
    "            **params_dict,\n",
    "        )\n",
    "\n",
    "        # Rename the index for the current result\n",
    "        res = res.rename(index={\"model\": f\"scenario {scenario}\"})\n",
    "\n",
    "        # Concatenate the result to the DataFrame\n",
    "        df = pd.concat([df, res], axis=0, ignore_index=False)\n",
    "\n",
    "    # Normalize by the values of scenario 0\n",
    "    # scenario_0_values = df.loc[df.index == 'scenario 0']\n",
    "    # df = df.divide(scenario_0_values.values.sum())\n",
    "\n",
    "    # Store the dataframe in the dictionary\n",
    "    dfs[method_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd37d8d58e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to excel file\n",
    "for method_name in methods_dict.keys():\n",
    "    dfs[method_name].to_excel(f\"tsas_endpoints_contributions_{method_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3726b599ecde9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the xlsx file at your wish for better plots, e.g. by merging low impact categories together and renaming the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b0141e8ce8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimport the data\n",
    "dfs = {\n",
    "    method_name: pd.read_excel(f\"tsas_endpoints_contributions_{method_name}.xlsx\", index_col=0)\n",
    "    for method_name in methods_dict.keys()\n",
    "}\n",
    "combined_df = pd.concat(dfs, names=[\"Method\", \"Scenario\"])  # .reset_index()#(level=0)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e8609c56d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Set up three subplots (one for each endpoint)\n",
    "clusters = combined_df.index.levels[0]\n",
    "inter_graph = 0\n",
    "maxi = np.max(np.sum(combined_df, axis=1))\n",
    "total_width = len(combined_df) + inter_graph * (len(clusters) - 1)\n",
    "fig = plt.figure(figsize=(total_width, 6))\n",
    "\n",
    "# Plot properties\n",
    "gridspec.GridSpec(1, total_width)\n",
    "axes = []\n",
    "palette = sns.color_palette(\"tab10\")\n",
    "# palette.insert(1, palette[1])  # Duplicate color for second position (climate change CO2) for third position (climate change Non-CO2)\n",
    "# hatches = [''] * len(combined_df.index)\n",
    "# hatches[2] = '//'\n",
    "\n",
    "ax_position = 0\n",
    "for cluster in clusters:\n",
    "    subset = combined_df.loc[cluster]\n",
    "    ax = subset.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        width=0.8,\n",
    "        ax=plt.subplot2grid((1, total_width), (0, ax_position), colspan=len(subset.index)),\n",
    "        color=palette,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"0.2\",\n",
    "    )\n",
    "    axes.append(ax)\n",
    "    ax.set_title(cluster.title(), fontsize=15)\n",
    "    ax.set_xlabel(\"\")\n",
    "    # ax.set_ylim(0,maxi*1.1)\n",
    "    ax_position += len(subset.index) + inter_graph\n",
    "    ax.tick_params(axis=\"x\", rotation=0, labelsize=11)\n",
    "\n",
    "    tick_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    wrapped_labels = [\n",
    "        \"\\n(\".join([label.split(\"(\")[0], label.split(\"(\")[1]]) if \"(\" in label else label\n",
    "        for label in tick_labels\n",
    "    ]\n",
    "    ax.set_xticklabels(wrapped_labels)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Apply hatches to the specific segment of the stacks\n",
    "    # for bar_group, hatch_pattern in zip(ax.containers, hatches[:len(subset.columns)]):\n",
    "    #    for bar in bar_group:\n",
    "    #        bar.set_hatch(hatch_pattern)\n",
    "\n",
    "for i in range(0, len(clusters)):\n",
    "    axes[i].legend().set_visible(False)\n",
    "for i in range(1, len(clusters) - 1):\n",
    "    axes[i].set_yticklabels(\"\")\n",
    "axes[-1].yaxis.tick_right()\n",
    "axes[-1].tick_params(axis=\"y\", labelsize=13)\n",
    "axes[0].tick_params(axis=\"y\", labelsize=13)\n",
    "axes[0].set_ylabel(\"Impacts relative to IS0\", fontsize=15)\n",
    "\n",
    "# Collect legend labels from all plots.\n",
    "entries = collections.OrderedDict()\n",
    "for ax in axes:\n",
    "    for handle, label in zip(*axes[0].get_legend_handles_labels()):\n",
    "        label_name = label.replace(\"_\", \" \").title()\n",
    "        entries[label_name] = handle\n",
    "legend = fig.legend(\n",
    "    entries.values(),\n",
    "    entries.keys(),\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    ncol=2,\n",
    "    fontsize=13,\n",
    "    title=\"Midpoint Category\",\n",
    "    title_fontsize=14,\n",
    ")\n",
    "\n",
    "# Set tight layout while keeping legend in the screen\n",
    "bbox = legend.get_window_extent(fig.canvas.get_renderer()).transformed(fig.transFigure.inverted())\n",
    "fig.tight_layout(rect=(0, bbox.y1, 1, 1), h_pad=0.5, w_pad=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49a27403b0869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
